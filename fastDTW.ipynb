{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bada716",
   "metadata": {},
   "source": [
    "# DTW Time checking and Multiprocessing\n",
    "\n",
    "First, let's import modules and define functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import multiprocessing\n",
    "from fastdtw import fastdtw\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ALL_LEADS = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "ecgno = np.load('./ecgno.npy')\n",
    "print(len(ecgno))\n",
    "\n",
    "dtw_ecgs = np.random.choice(ecgno, 100000)\n",
    "train_id = dtw_ecgs[:60000]\n",
    "val_id = dtw_ecgs[60000:80000]\n",
    "test_id = dtw_ecgs[80000:]\n",
    "\n",
    "manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "\n",
    "def load_ecg(\n",
    "    hd5: h5py.File, date: str,\n",
    "    target_length: int = 2500, \n",
    "    leads: List[str] = ALL_LEADS,\n",
    "):\n",
    "    out = np.empty((target_length, len(leads)))\n",
    "    for i, lead in enumerate(leads):\n",
    "        lead_array = hd5[\"ecg\"][date][lead][()]\n",
    "        out[:, i] = np.interp(\n",
    "            np.linspace(0, 1, target_length),\n",
    "            np.linspace(0, 1, lead_array.shape[0]),\n",
    "            lead_array,\n",
    "        )\n",
    "    return out\n",
    "\n",
    "# def fastdtw(ecg1, ecg2):\n",
    "#     return fastdtw.fastdtw(ecg1, ecg2)[0]\n",
    "\n",
    "def calc_dtw_each(ecg1_id, ecg2_id, dtw_matrix):\n",
    "    if dtw_matrix[i][j] == 0:\n",
    "        with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "            print('loaded hd5')\n",
    "            ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "        with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "            ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "\n",
    "        print ('loaded ecg')\n",
    "        dtw_val = fastdtw(ecg1, ecg2)[0]\n",
    "        dtw_matrix[i][j] = dtw_val\n",
    "        dtw_matrix[j][i] = dtw_val\n",
    "    else:\n",
    "        print('multiple calculation'+ecg1_id+ecg2_id)\n",
    "        \n",
    "    return dtw_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg1_id.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c64496",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg1_id = ecgno[0]\n",
    "ecg2_id = ecgno[1]\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "for i in range(12):\n",
    "    plt.plot(ecg1[:,i].T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ecg1.shape, ecg2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17de0d8",
   "metadata": {},
   "source": [
    "# DTW surrogate model speed Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb52330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args, device=None, valid=False, dtw=False, finetuning=False, dml_model=None):\n",
    "    if valid:\n",
    "        model = Classifier(args=args) #two layer fc classifier (with BN, ReLU, Dropout)\n",
    "        \n",
    "    elif finetuning:        \n",
    "        # Load model for finetuning\n",
    "        model = Finetune_Classifier(args, dml_model)\n",
    "        print('model for finetuning')\n",
    "        \n",
    "    else:\n",
    "        if args.model == \"cnn\":\n",
    "            if args.dtw or dtw:\n",
    "                model = resnet18_dtw(pretrained=args.pretrain, args=args)\n",
    "            else:\n",
    "                model = resnet18(pretrained=args.pretrain, args=args)\n",
    "\n",
    "        elif args.model == \"cnn_prev\":\n",
    "            model = models.resnet18(pretrained=False).to(device)\n",
    "            model.conv1 = nn.Conv2d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\n",
    "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "            model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "\n",
    "        else:\n",
    "            model_module = importlib.import_module(\"model.\" + args.model)\n",
    "            model_class = getattr(model_module, args.model.upper())\n",
    "            model = model_class(args)\n",
    "\n",
    "    model = model.to(device)\n",
    "    # model = nn.DataParallel(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db3fc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_ecg(\n",
    "#     hd5: h5py.File, date: str,\n",
    "#     target_length: int = 2500, \n",
    "#     leads: List[str] = ALL_LEADS,\n",
    "# ):\n",
    "#     out = np.empty((target_length, len(leads)))\n",
    "#     for i, lead in enumerate(leads):\n",
    "#         lead_array = hd5[\"ecg\"][date][lead][()]\n",
    "#         out[:, i] = np.interp(\n",
    "#             np.linspace(0, 1, target_length),\n",
    "#             np.linspace(0, 1, lead_array.shape[0]),\n",
    "#             lead_array,\n",
    "#         )\n",
    "#     return out\n",
    "\n",
    "hd5 = h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\")\n",
    "lead_array = hd5[\"ecg\"][ecg1_id.split('_')[-1]]['II'][()][:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lead_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acfd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lead_array.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.plot(ecg2[:,i].T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423d1fb",
   "metadata": {},
   "source": [
    "# Dynamic Time Warping\n",
    "\n",
    "In this step I tried multiple versions of DTW \n",
    "\n",
    "Todo: Check whether each dtw method provides multidimensional distance calculation (for 12 lead ECGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21bcd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastDTW: https://github.com/DynamicTimeWarping/dtw-python\n",
    "ecg1_id = ecgno[0]\n",
    "ecg2_id = ecgno[1]\n",
    "\n",
    "now = datetime.now()\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "\n",
    "print ('loaded ecg')\n",
    "dtw_val, route = fastdtw(ecg1, ecg2)\n",
    "print(route)\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "\n",
    "print(difference)\n",
    "print(dtw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a13340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast dtw channelwise\n",
    "now = datetime.now()\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "\n",
    "for lead in tqdm(range(12)):\n",
    "    x = ecg1[:, lead]\n",
    "    y = ecg2[:, lead]\n",
    "    \n",
    "    d, route = fastdtw(x, y)\n",
    "    dtw_d.append(d)\n",
    "    print (d)\n",
    "\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(np.mean(dtw_d))\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastDTW: https://github.com/DynamicTimeWarping/dtw-python\n",
    "ecg1_id = ecgno[0]\n",
    "ecg2_id = ecgno[1]\n",
    "dtw_d = []\n",
    "\n",
    "now = datetime.now()\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "\n",
    "print ('loaded ecg')\n",
    "dtw_val, route = fastdtw(ecg1, ecg2)\n",
    "print(route)\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "\n",
    "for lead in tqdm(range(12)):\n",
    "    x = ecg1[:, lead]\n",
    "    y = ecg2[:, lead]\n",
    "    \n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(x, y, dist=manhattan_distance)\n",
    "    dtw_d.append(d)\n",
    "    print (d)\n",
    "\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(np.mean(dtw_d))\n",
    "\n",
    "print(difference)\n",
    "print(dtw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW: https://github.com/markdregan/K-Nearest-Neighbors-with-Dynamic-Time-Warping\n",
    "from dtw import dtw\n",
    "manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "dtw_d = []\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "\n",
    "for lead in tqdm(range(12)):\n",
    "    x = ecg1[:, lead]\n",
    "    y = ecg2[:, lead]\n",
    "    \n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(x, y, dist=manhattan_distance)\n",
    "    dtw_d.append(d)\n",
    "    print (d)\n",
    "\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(np.mean(dtw_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW-python: https://github.com/DynamicTimeWarping/dtw-python\n",
    "import numpy as np\n",
    "\n",
    "## A noisy sine wave as query\n",
    "idx = np.linspace(0,6.28,num=100)\n",
    "query = np.sin(idx) + np.random.uniform(size=100)/10.0\n",
    "\n",
    "## A cosine is for template; sin and cos are offset by 25 samples\n",
    "template = np.cos(idx)\n",
    "\n",
    "## Find the best match with the canonical recursion formula\n",
    "from dtw import *\n",
    "\n",
    "now = datetime.now()\n",
    "ecg1_id = ecgno[0]\n",
    "ecg2_id = ecgno[1]\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "    \n",
    "alignment = dtw(ecg1, ecg2, keep_internals=True)\n",
    "\n",
    "## Display the warping curve, i.e. the alignment curve\n",
    "alignment.plot(type=\"threeway\")\n",
    "\n",
    "## Align and plot with the Rabiner-Juang type VI-c unsmoothed recursion\n",
    "dtw(query, template, keep_internals=True, \n",
    "    step_pattern=rabinerJuangStepPattern(6, \"c\"))\\\n",
    "    .plot(type=\"twoway\",offset=-2)\n",
    "\n",
    "## See the recursion relation, as formula and diagram\n",
    "print(rabinerJuangStepPattern(6,\"c\"))\n",
    "rabinerJuangStepPattern(6,\"c\").plot()\n",
    "\n",
    "## And much more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtaidistance: faster per some report from others\n",
    "from dtaidistance import dtw\n",
    "dtw_d = []\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "print('loaded hd5')\n",
    "\n",
    "for lead in tqdm(range(12)):\n",
    "    x = ecg1[:, lead]\n",
    "    y = ecg2[:, lead]\n",
    "    \n",
    "    d = dtw(x, y, use_mp=True)\n",
    "    dtw_d.append(d)\n",
    "    print (d)\n",
    "\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(np.mean(dtw_d))\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee05aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtaidistance: faster per some report from others\n",
    "from dtaidistance import dtw_ndim\n",
    "dtw_d = []\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "print('loaded hd5')\n",
    "\n",
    "print(dtw_ndim.distance(ecg1, ecg2))\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9479d6",
   "metadata": {},
   "source": [
    "# MultiProcessing\n",
    "\n",
    "Now let's try multiprocessing with dtaidistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "num_cores = multiprocessing.cpu_count() - 1 # total 80\n",
    "print(num_cores)\n",
    "\n",
    "DTW_MATRIX = np.zeros((len(train_id), len(train_id)))\n",
    "prod = itertools.product(train_id, train_id)\n",
    "print('prepared ids and pairs')\n",
    "\n",
    "def calc_dtw_each(ecg1_id, ecg2_id):\n",
    "    now = datetime.now()\n",
    "    if DTW_MATRIX[i][j] == 0:\n",
    "        with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as e1:\n",
    "            print('loaded hd5')\n",
    "            ecg1 = load_ecg(e1, ecg1_id.split('_')[-1])\n",
    "        with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as e2:\n",
    "            ecg2 = load_ecg(e2, ecg2_id.split('_')[-1])\n",
    "\n",
    "        print ('loaded ecg')\n",
    "        dtw_d = np.mean([dtw_ndim.distance(ecg1[:, lead], ecg2[:, lead])[0] for lead in range(12)])\n",
    "        DTW_MATRIX[i][j] = dtw_val\n",
    "        DTW_MATRIX[j][i] = dtw_val \n",
    "    later = datetime.now()\n",
    "    difference = (later - now).total_seconds()\n",
    "    print(difference)\n",
    "    return dtw_matrix\n",
    "\n",
    "# Parallel(n_jobs=num_cores)(delayed(calculate_dtw)(train_id) for j in range(len(train_id)))\n",
    "# print (time.time() - init)\n",
    "\n",
    "print('preparing multiprocesing')\n",
    "pool = multiprocessing.Pool(num_cores)\n",
    "for _ in tqdm.tqdm(pool.imap_unordered(calc_dtw_each, prod), total=len(prod)):\n",
    "    pass\n",
    "pool.close()\n",
    "# pool.map(calc_dtw_each, prod)\n",
    "\n",
    "print('saving files...')\n",
    "np.save('./dtw_train_dtai.npy', DTW_MATRIX)\n",
    "# np.save('./dtw_val.npy', dtw_val)\n",
    "# np.save('./dtw_test.npy', dtw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtaidistance: faster per some report from others\n",
    "from dtaidistance import dtw_ndim\n",
    "dtw_d = []\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "print('loaded hd5')\n",
    "\n",
    "print(dtw_ndim.distance_matrix(ecg1, ecg2, use_mp=True))\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[] for i in range(N)]\n",
    "\n",
    "def calc_dtw_each(ecg1_id, ecg2_id, dtw_matrix):\n",
    "    if dtw_matrix[i][j] == 0:\n",
    "        with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "            print('loaded hd5')\n",
    "            ecg1 = load_ecg(hd5, ecg1_id.split('_')[-1])\n",
    "        with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(batch[j].split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "            ecg2 = load_ecg(hd5, ecg2_id.split('_')[-1])\n",
    "\n",
    "        print ('loaded ecg')\n",
    "        dtw_val = fastdtw(ecg1, ecg2)\n",
    "        dtw_matrix[i][j] = dtw_val\n",
    "        dtw_matrix[j][i] = dtw_val\n",
    "    else:\n",
    "        print('multiple calculation'+ecg1_id+ecg2_id)\n",
    "        \n",
    "    return dtw_matrix\n",
    "\n",
    "dtw_matrix = np.zeros((len(train_id), len(train_id)))\n",
    "for i in tqdm(range(len(train_id))):\n",
    "    dtw_matrix = Parallel(n_jobs=num_cores)(delayed(calc_dtw_each)(train_id[i],train_id[j], dtw_matrix) for j in range(len(train_id)) )\n",
    "\n",
    "dtw_val = pool.map(calculate_dtw, val_id, val_id)\n",
    "dtw_test = pool.map(calculate_dtw, test_id)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# dtw_train = calculate_dtw(train_id)\n",
    "# dtw_val = calculate_dtw(val_id)\n",
    "# dtw_test = calculate_dtw(test_id)\n",
    "\n",
    "np.save('./dtw_train.npy', dtw_train)\n",
    "np.save('./dtw_val.npy', dtw_val)\n",
    "np.save('./dtw_test.npy', dtw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a08850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA dtw channelwise\n",
    "import torch\n",
    "from utils.soft_dtw_cuda import SoftDTW\n",
    "\n",
    "ecg1_id = ecgno[0]\n",
    "ecg2_id = ecgno[1]\n",
    "\n",
    "device = torch.device('cuda')\n",
    "sdtw = SoftDTW(use_cuda=True, gamma=0.1)\n",
    "now = datetime.now()\n",
    "print('start loading files')\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg1_id.split('_')[0], ecg1_id.split('_')[1]), \"r\") as hd5:\n",
    "    print('loaded hd5')\n",
    "    ecg1 = torch.from_numpy(load_ecg(hd5, ecg1_id.split('_')[-1])).to(device)\n",
    "with h5py.File(\"/storage/shared/ecg/{}/{}.hd5\".format(ecg2_id.split('_')[0], ecg2_id.split('_')[1]), \"r\") as hd5:\n",
    "    ecg2 = torch.from_numpy(load_ecg(hd5, ecg2_id.split('_')[-1])).to(device)\n",
    "\n",
    "for lead in tqdm(range(12)):\n",
    "    x = ecg1[:, lead]\n",
    "    y = ecg2[:, lead]\n",
    "\n",
    "    d = sdtw(x, y)\n",
    "    dtw_d.append(d)\n",
    "    print (d)\n",
    "\n",
    "later = datetime.now()\n",
    "difference = (later - now).total_seconds()\n",
    "print(np.mean(dtw_d))\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c9861",
   "metadata": {},
   "source": [
    "# Define DTW ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79828a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ecgno = np.load('./ecgno.npy')\n",
    "print(len(ecgno))\n",
    "\n",
    "dtw_ecgs = np.random.choice(ecgno, 10000)\n",
    "train_id = dtw_ecgs[:6000]\n",
    "val_id = dtw_ecgs[6000:8000]\n",
    "test_id = dtw_ecgs[8000:]\n",
    "\n",
    "np.save('./stores/dtw_trainid.npy', train_id) #6000\n",
    "np.save('./stores/dtw_validid.npy', val_id) #2000\n",
    "np.save('./stores/dtw_testid.npy', test_id) #2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f53f54",
   "metadata": {},
   "source": [
    "# Plotting DTW\n",
    "\n",
    "Let's find out the distribution of DTW and get the sense on what's high and low value of DTW on ECG\n",
    "--> How is this different from literature reports? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5666285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_MATRIX_TRAIN = np.load('./stores/dtw_matrix_train.npy').flatten()\n",
    "DTW_MATRIX_VALID = np.load('./stores/dtw_matrix_valid.npy').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DTW_MATRIX_TRAIN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22aa7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DTW_MATRIX_VALID)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29445778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(DTW_MATRIX_TRAIN*1000000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419706d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_MATRIX_TRAIN.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DTW_MATRIX_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(DTW_MATRIX_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85030a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=DTW_MATRIX_TRAIN, x=\"distance\", hue=\"method\",\n",
    "    log_scale=True, element=\"step\", fill=False,\n",
    "    cumulative=True, stat=\"density\", common_norm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80560b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_MATRIX_TRAIN = np.load('./stores/dtw_matrix_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fe7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_MATRIX_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02384f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_MATRIX_TRAIN[105:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470def3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
